{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG16_Keras",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EczyBBusFwgG",
        "colab_type": "text"
      },
      "source": [
        "# VGG16 And CIFAR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2AfrKOcFq-E",
        "colab_type": "code",
        "outputId": "43aa1c73-ca6d-4812-c4b9-1235df7bb8e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A93xGqBKzN2a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "from keras.layers import *\n",
        "from keras.regularizers import l2\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, Callback, LearningRateScheduler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zHRj3smGJxX",
        "colab_type": "code",
        "outputId": "f24b50d3-f3c2-4fe8-a0d5-5097951b95f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoF7gzskOy1c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Before preprocessing the dataset with VGG16 network, checking the data\n",
        "for i in range(10,1,-1):\n",
        "    img = x_train[i].reshape(32,32,3)\n",
        "    plt.imshow(img)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wP-OMLJcMOvo",
        "colab_type": "text"
      },
      "source": [
        "Normalize inputs for zero mean and unit variance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gV9F_QveMKqY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(x_train,x_test):\n",
        "        mean = np.mean(x_train,axis=(0,1,2,3))\n",
        "        std = np.std(x_train, axis=(0, 1, 2, 3))\n",
        "        x_train = (x_train-mean)/(std+1e-7)\n",
        "        x_test = (x_test-mean)/(std+1e-7)\n",
        "        return x_train, x_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foEfQEtLMq8u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test = normalize(x_train, x_test)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1BiT71vzQRO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_classes = 100\n",
        "\n",
        "y_train = to_categorical(y_train, target_classes)\n",
        "y_test = to_categorical(y_test, target_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJuOAwXFQynO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def LearningRateSchedulerOptimser(epoch):\n",
        "  return learning_rate * (0.5 ** (epoch // lr_drop))\n",
        "\n",
        "reduce_lr = LearningRateScheduler(LearningRateSchedulerOptimser)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKyadLN7RNP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator()\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOmUh-z3SY7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weight_decay = 0.0005\n",
        "input_shape = (32,32,3)\n",
        "batch_size = 128\n",
        "epochs = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWt3ClIpzSIG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "103ad61f-a3c6-4790-896f-4b978af9b0d8"
      },
      "source": [
        "# Trying to set different rates. Best seems to be 0.1\n",
        "learning_rate = 0.1\n",
        "lr_decay = 1e-6\n",
        "lr_drop = 20\n",
        "print('test')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqcFtLjxS8Iz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VGG16:\n",
        "      def build(self):\n",
        "\n",
        "          model = keras.models.Sequential()\n",
        "\n",
        "          model.add(Conv2D(64, (3, 3), padding='same', input_shape=input_shape, kernel_regularizer=l2(weight_decay)))\n",
        "          model.add(Activation('relu'))\n",
        "          model.add(BatchNormalization())\n",
        "          model.add(Dropout(0.3))\n",
        "\n",
        "          model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=l2(weight_decay)))\n",
        "          model.add(Activation('relu'))\n",
        "          model.add(BatchNormalization())\n",
        "\n",
        "          model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "          model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=l2(weight_decay)))\n",
        "          model.add(Activation('relu'))\n",
        "          model.add(BatchNormalization())\n",
        "          model.add(Dropout(0.4))\n",
        "\n",
        "          model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=l2(weight_decay)))\n",
        "          model.add(Activation('relu'))\n",
        "          model.add(BatchNormalization())\n",
        "          model.add(BatchNormalization())\n",
        "\n",
        "          model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "          model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=l2(weight_decay)))\n",
        "          model.add(Activation('relu'))\n",
        "          model.add(BatchNormalization())\n",
        "          model.add(Dropout(0.4))\n",
        "\n",
        "          model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=l2(weight_decay)))\n",
        "          model.add(Activation('relu'))\n",
        "          model.add(BatchNormalization())\n",
        "          model.add(Dropout(0.4))\n",
        "\n",
        "\n",
        "          model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=l2(weight_decay)))\n",
        "          model.add(Activation('relu'))\n",
        "          model.add(BatchNormalization())\n",
        "\n",
        "          model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "          model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=l2(weight_decay)))\n",
        "          model.add(Activation('relu'))\n",
        "          model.add(BatchNormalization())\n",
        "          model.add(Dropout(0.4))\n",
        "\n",
        "          model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=l2(weight_decay)))\n",
        "          model.add(Activation('relu'))\n",
        "          model.add(BatchNormalization())\n",
        "          model.add(Dropout(0.4))\n",
        "\n",
        "          model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=l2(weight_decay)))\n",
        "          model.add(Activation('relu'))\n",
        "          model.add(BatchNormalization())\n",
        "\n",
        "          model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "          model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=l2(weight_decay)))\n",
        "          model.add(Activation('relu'))\n",
        "          model.add(BatchNormalization())\n",
        "          model.add(Dropout(0.4))\n",
        "\n",
        "          model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=l2(weight_decay)))\n",
        "          model.add(Activation('relu'))\n",
        "          model.add(BatchNormalization())\n",
        "          model.add(Dropout(0.4))\n",
        "\n",
        "          model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=l2(weight_decay)))\n",
        "          model.add(Activation('relu'))\n",
        "          model.add(BatchNormalization())\n",
        "\n",
        "          model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "          model.add(Dropout(0.5))\n",
        "\n",
        "          model.add(Flatten())\n",
        "          model.add(Dense(512,kernel_regularizer=l2(weight_decay)))\n",
        "          model.add(Activation('relu'))\n",
        "          model.add(BatchNormalization())\n",
        "\n",
        "          model.add(Dropout(0.5))\n",
        "          model.add(Dense(target_classes))\n",
        "          model.add(Activation('softmax'))\n",
        "          return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNuZelui7Med",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=VGG16().build()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqzg1oy_UFbf",
        "colab_type": "code",
        "outputId": "4e1fed82-db62-4bc8-a43a-ce3a54007a71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 64)        1792      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 64)          36928     \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 8, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 8, 8, 64)          36928     \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 8, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 8, 8, 64)          36928     \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 8, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 4, 4, 64)          36928     \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 4, 4, 64)          256       \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 4, 4, 512)         295424    \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 4, 4, 512)         2048      \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 4, 4, 512)         2048      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 2, 2, 512)         2048      \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 2, 2, 512)         2048      \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 2, 2, 512)         2048      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 100)               51300     \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 100)               0         \n",
            "=================================================================\n",
            "Total params: 10,323,492\n",
            "Trainable params: 10,316,196\n",
            "Non-trainable params: 7,296\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qshl-WoIUVm3",
        "colab_type": "text"
      },
      "source": [
        "Visualize and export the model's summary image as a png file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3LjqPubUJuv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# keras.utils.plot_model(model, \"vgg16.png\", show_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "empvtxn5Uh0Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=optimizers.SGD(lr=learning_rate, decay=lr_decay, momentum=0.9, nesterov=True), metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-D7AQU3SBFG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "early_stop = EarlyStopping(monitor='accuracy', patience=5, mode='max')\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "callbacks_list = [tensorboard_callback, reduce_lr]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJOFqtndVJ-7",
        "colab_type": "code",
        "outputId": "993c01ab-0294-4028-a9a6-65971816f939",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit_generator(datagen.flow(x_train, y_train,batch_size=batch_size),\n",
        "                            steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "                            epochs=epochs,\n",
        "                            validation_data=(x_test, y_test),callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "390/390 [==============================] - 32s 82ms/step - loss: 13.7299 - accuracy: 0.0295 - val_loss: 10.6573 - val_accuracy: 0.0248\n",
            "Epoch 2/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 8.4837 - accuracy: 0.0513 - val_loss: 7.3169 - val_accuracy: 0.0288\n",
            "Epoch 3/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 6.1017 - accuracy: 0.0651 - val_loss: 5.7262 - val_accuracy: 0.0391\n",
            "Epoch 4/100\n",
            "390/390 [==============================] - 22s 55ms/step - loss: 4.9833 - accuracy: 0.0821 - val_loss: 4.8347 - val_accuracy: 0.0683\n",
            "Epoch 5/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 4.4627 - accuracy: 0.0937 - val_loss: 4.5933 - val_accuracy: 0.0789\n",
            "Epoch 6/100\n",
            "390/390 [==============================] - 22s 55ms/step - loss: 4.1948 - accuracy: 0.1086 - val_loss: 4.1703 - val_accuracy: 0.1124\n",
            "Epoch 7/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 4.0270 - accuracy: 0.1230 - val_loss: 4.1716 - val_accuracy: 0.1178\n",
            "Epoch 8/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 3.9065 - accuracy: 0.1442 - val_loss: 4.1727 - val_accuracy: 0.1312\n",
            "Epoch 9/100\n",
            "390/390 [==============================] - 22s 57ms/step - loss: 3.8143 - accuracy: 0.1712 - val_loss: 4.0126 - val_accuracy: 0.1493\n",
            "Epoch 10/100\n",
            "390/390 [==============================] - 22s 57ms/step - loss: 3.7583 - accuracy: 0.1911 - val_loss: 3.7164 - val_accuracy: 0.2126\n",
            "Epoch 11/100\n",
            "390/390 [==============================] - 22s 57ms/step - loss: 3.6727 - accuracy: 0.2196 - val_loss: 3.6310 - val_accuracy: 0.2346\n",
            "Epoch 12/100\n",
            "390/390 [==============================] - 22s 57ms/step - loss: 3.6229 - accuracy: 0.2370 - val_loss: 3.8739 - val_accuracy: 0.2073\n",
            "Epoch 13/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 3.5993 - accuracy: 0.2528 - val_loss: 3.7003 - val_accuracy: 0.2385\n",
            "Epoch 14/100\n",
            "390/390 [==============================] - 22s 57ms/step - loss: 3.5909 - accuracy: 0.2641 - val_loss: 3.5756 - val_accuracy: 0.2758\n",
            "Epoch 15/100\n",
            "390/390 [==============================] - 22s 57ms/step - loss: 3.5721 - accuracy: 0.2761 - val_loss: 3.5299 - val_accuracy: 0.2913\n",
            "Epoch 16/100\n",
            "390/390 [==============================] - 22s 57ms/step - loss: 3.5725 - accuracy: 0.2820 - val_loss: 3.5410 - val_accuracy: 0.3031\n",
            "Epoch 17/100\n",
            "390/390 [==============================] - 22s 57ms/step - loss: 3.5714 - accuracy: 0.2873 - val_loss: 3.4923 - val_accuracy: 0.3110\n",
            "Epoch 18/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 3.5477 - accuracy: 0.3018 - val_loss: 3.6332 - val_accuracy: 0.2856\n",
            "Epoch 19/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 3.5535 - accuracy: 0.3049 - val_loss: 3.5376 - val_accuracy: 0.3177\n",
            "Epoch 20/100\n",
            "390/390 [==============================] - 22s 57ms/step - loss: 3.5510 - accuracy: 0.3113 - val_loss: 3.7057 - val_accuracy: 0.2965\n",
            "Epoch 21/100\n",
            "390/390 [==============================] - 22s 57ms/step - loss: 3.2689 - accuracy: 0.3629 - val_loss: 3.2722 - val_accuracy: 0.3551\n",
            "Epoch 22/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 3.1229 - accuracy: 0.3715 - val_loss: 3.0523 - val_accuracy: 0.3905\n",
            "Epoch 23/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 3.0891 - accuracy: 0.3791 - val_loss: 3.1674 - val_accuracy: 0.3647\n",
            "Epoch 24/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 3.0756 - accuracy: 0.3768 - val_loss: 3.0341 - val_accuracy: 0.3954\n",
            "Epoch 25/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 3.0666 - accuracy: 0.3832 - val_loss: 3.0952 - val_accuracy: 0.3833\n",
            "Epoch 26/100\n",
            "390/390 [==============================] - 22s 57ms/step - loss: 3.0671 - accuracy: 0.3886 - val_loss: 3.1507 - val_accuracy: 0.3772\n",
            "Epoch 27/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 3.0644 - accuracy: 0.3937 - val_loss: 3.1167 - val_accuracy: 0.3940\n",
            "Epoch 28/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 3.0540 - accuracy: 0.3972 - val_loss: 2.9376 - val_accuracy: 0.4309\n",
            "Epoch 29/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 3.0589 - accuracy: 0.3977 - val_loss: 2.9346 - val_accuracy: 0.4295\n",
            "Epoch 30/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 3.0624 - accuracy: 0.4032 - val_loss: 3.1599 - val_accuracy: 0.3919\n",
            "Epoch 31/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 3.0613 - accuracy: 0.4066 - val_loss: 3.0322 - val_accuracy: 0.4150\n",
            "Epoch 32/100\n",
            "390/390 [==============================] - 22s 57ms/step - loss: 3.0624 - accuracy: 0.4085 - val_loss: 3.0757 - val_accuracy: 0.4110\n",
            "Epoch 33/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 3.0652 - accuracy: 0.4113 - val_loss: 2.9512 - val_accuracy: 0.4362\n",
            "Epoch 34/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 3.0565 - accuracy: 0.4175 - val_loss: 3.0133 - val_accuracy: 0.4321\n",
            "Epoch 35/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 3.0607 - accuracy: 0.4190 - val_loss: 2.9273 - val_accuracy: 0.4451\n",
            "Epoch 36/100\n",
            "390/390 [==============================] - 22s 57ms/step - loss: 3.0628 - accuracy: 0.4218 - val_loss: 3.2001 - val_accuracy: 0.4047\n",
            "Epoch 37/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 3.0814 - accuracy: 0.4220 - val_loss: 3.0086 - val_accuracy: 0.4339\n",
            "Epoch 38/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 3.0780 - accuracy: 0.4215 - val_loss: 3.1005 - val_accuracy: 0.4284\n",
            "Epoch 39/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 3.0751 - accuracy: 0.4275 - val_loss: 3.0292 - val_accuracy: 0.4455\n",
            "Epoch 40/100\n",
            "390/390 [==============================] - 22s 57ms/step - loss: 3.0766 - accuracy: 0.4282 - val_loss: 3.0418 - val_accuracy: 0.4330\n",
            "Epoch 41/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 2.8467 - accuracy: 0.4758 - val_loss: 2.6977 - val_accuracy: 0.5080\n",
            "Epoch 42/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 2.7255 - accuracy: 0.4880 - val_loss: 2.6870 - val_accuracy: 0.4954\n",
            "Epoch 43/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 2.6770 - accuracy: 0.4920 - val_loss: 2.7199 - val_accuracy: 0.4839\n",
            "Epoch 44/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 2.6549 - accuracy: 0.4924 - val_loss: 2.6471 - val_accuracy: 0.5035\n",
            "Epoch 45/100\n",
            "390/390 [==============================] - 22s 57ms/step - loss: 2.6524 - accuracy: 0.4931 - val_loss: 2.6608 - val_accuracy: 0.4927\n",
            "Epoch 46/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 2.6372 - accuracy: 0.4967 - val_loss: 2.6512 - val_accuracy: 0.4962\n",
            "Epoch 47/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 2.6468 - accuracy: 0.4960 - val_loss: 2.6790 - val_accuracy: 0.4929\n",
            "Epoch 48/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 2.6355 - accuracy: 0.5001 - val_loss: 2.6081 - val_accuracy: 0.5184\n",
            "Epoch 49/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 2.6372 - accuracy: 0.5048 - val_loss: 2.6606 - val_accuracy: 0.5058\n",
            "Epoch 50/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 2.6593 - accuracy: 0.4996 - val_loss: 2.6514 - val_accuracy: 0.5128\n",
            "Epoch 51/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 2.6556 - accuracy: 0.5076 - val_loss: 2.6715 - val_accuracy: 0.5059\n",
            "Epoch 52/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 2.6661 - accuracy: 0.5092 - val_loss: 2.7310 - val_accuracy: 0.4938\n",
            "Epoch 53/100\n",
            "390/390 [==============================] - 22s 57ms/step - loss: 2.6632 - accuracy: 0.5125 - val_loss: 2.7192 - val_accuracy: 0.5039\n",
            "Epoch 54/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 2.6793 - accuracy: 0.5118 - val_loss: 2.6894 - val_accuracy: 0.5114\n",
            "Epoch 55/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 2.6870 - accuracy: 0.5124 - val_loss: 2.7799 - val_accuracy: 0.5012\n",
            "Epoch 56/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 2.7083 - accuracy: 0.5115 - val_loss: 2.7605 - val_accuracy: 0.5080\n",
            "Epoch 57/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 2.6992 - accuracy: 0.5163 - val_loss: 2.7625 - val_accuracy: 0.5109\n",
            "Epoch 58/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 2.7174 - accuracy: 0.5148 - val_loss: 2.7358 - val_accuracy: 0.5173\n",
            "Epoch 59/100\n",
            "390/390 [==============================] - 22s 57ms/step - loss: 2.7216 - accuracy: 0.5162 - val_loss: 2.8048 - val_accuracy: 0.5096\n",
            "Epoch 60/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 2.7224 - accuracy: 0.5204 - val_loss: 2.6721 - val_accuracy: 0.5364\n",
            "Epoch 61/100\n",
            "390/390 [==============================] - 22s 55ms/step - loss: 2.5305 - accuracy: 0.5654 - val_loss: 2.5339 - val_accuracy: 0.5616\n",
            "Epoch 62/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 2.4187 - accuracy: 0.5815 - val_loss: 2.5064 - val_accuracy: 0.5630\n",
            "Epoch 63/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 2.3801 - accuracy: 0.5867 - val_loss: 2.5593 - val_accuracy: 0.5534\n",
            "Epoch 64/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 2.3624 - accuracy: 0.5847 - val_loss: 2.4886 - val_accuracy: 0.5610\n",
            "Epoch 65/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 2.3347 - accuracy: 0.5903 - val_loss: 2.4640 - val_accuracy: 0.5683\n",
            "Epoch 66/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 2.3322 - accuracy: 0.5865 - val_loss: 2.5493 - val_accuracy: 0.5504\n",
            "Epoch 67/100\n",
            "390/390 [==============================] - 22s 57ms/step - loss: 2.3283 - accuracy: 0.5892 - val_loss: 2.5978 - val_accuracy: 0.5480\n",
            "Epoch 68/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 2.3247 - accuracy: 0.5910 - val_loss: 2.5228 - val_accuracy: 0.5609\n",
            "Epoch 69/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 2.3221 - accuracy: 0.5928 - val_loss: 2.5482 - val_accuracy: 0.5550\n",
            "Epoch 70/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 2.3094 - accuracy: 0.5968 - val_loss: 2.5379 - val_accuracy: 0.5650\n",
            "Epoch 71/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 2.3301 - accuracy: 0.5931 - val_loss: 2.4940 - val_accuracy: 0.5665\n",
            "Epoch 72/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 2.3276 - accuracy: 0.5965 - val_loss: 2.5067 - val_accuracy: 0.5675\n",
            "Epoch 73/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 2.3399 - accuracy: 0.5946 - val_loss: 2.5483 - val_accuracy: 0.5648\n",
            "Epoch 74/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 2.3466 - accuracy: 0.5932 - val_loss: 2.6059 - val_accuracy: 0.5526\n",
            "Epoch 75/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 2.3429 - accuracy: 0.5968 - val_loss: 2.5665 - val_accuracy: 0.5637\n",
            "Epoch 76/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 2.3475 - accuracy: 0.6019 - val_loss: 2.5740 - val_accuracy: 0.5644\n",
            "Epoch 77/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 2.3555 - accuracy: 0.6017 - val_loss: 2.5196 - val_accuracy: 0.5763\n",
            "Epoch 78/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 2.3594 - accuracy: 0.6044 - val_loss: 2.6294 - val_accuracy: 0.5599\n",
            "Epoch 79/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 2.3637 - accuracy: 0.6040 - val_loss: 2.5826 - val_accuracy: 0.5735\n",
            "Epoch 80/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 2.3580 - accuracy: 0.6070 - val_loss: 2.5932 - val_accuracy: 0.5742\n",
            "Epoch 81/100\n",
            "390/390 [==============================] - 22s 57ms/step - loss: 2.1954 - accuracy: 0.6485 - val_loss: 2.4419 - val_accuracy: 0.5992\n",
            "Epoch 82/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 2.1155 - accuracy: 0.6624 - val_loss: 2.5191 - val_accuracy: 0.5859\n",
            "Epoch 83/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 2.0675 - accuracy: 0.6683 - val_loss: 2.4814 - val_accuracy: 0.5937\n",
            "Epoch 84/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 2.0402 - accuracy: 0.6749 - val_loss: 2.4921 - val_accuracy: 0.5900\n",
            "Epoch 85/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 2.0241 - accuracy: 0.6760 - val_loss: 2.4503 - val_accuracy: 0.5974\n",
            "Epoch 86/100\n",
            "390/390 [==============================] - 22s 57ms/step - loss: 2.0125 - accuracy: 0.6761 - val_loss: 2.4644 - val_accuracy: 0.5955\n",
            "Epoch 87/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 1.9994 - accuracy: 0.6772 - val_loss: 2.4517 - val_accuracy: 0.6002\n",
            "Epoch 88/100\n",
            "390/390 [==============================] - 22s 57ms/step - loss: 1.9990 - accuracy: 0.6774 - val_loss: 2.4679 - val_accuracy: 0.5906\n",
            "Epoch 89/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 1.9794 - accuracy: 0.6804 - val_loss: 2.5207 - val_accuracy: 0.5861\n",
            "Epoch 90/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 1.9793 - accuracy: 0.6820 - val_loss: 2.5228 - val_accuracy: 0.5856\n",
            "Epoch 91/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 1.9897 - accuracy: 0.6794 - val_loss: 2.4550 - val_accuracy: 0.5969\n",
            "Epoch 92/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 1.9681 - accuracy: 0.6843 - val_loss: 2.4928 - val_accuracy: 0.5952\n",
            "Epoch 93/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 1.9702 - accuracy: 0.6841 - val_loss: 2.4731 - val_accuracy: 0.5944\n",
            "Epoch 94/100\n",
            "390/390 [==============================] - 22s 57ms/step - loss: 1.9572 - accuracy: 0.6845 - val_loss: 2.4347 - val_accuracy: 0.6011\n",
            "Epoch 95/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 1.9632 - accuracy: 0.6852 - val_loss: 2.4980 - val_accuracy: 0.5959\n",
            "Epoch 96/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 1.9611 - accuracy: 0.6878 - val_loss: 2.4832 - val_accuracy: 0.5916\n",
            "Epoch 97/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 1.9572 - accuracy: 0.6897 - val_loss: 2.4849 - val_accuracy: 0.5989\n",
            "Epoch 98/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 1.9559 - accuracy: 0.6881 - val_loss: 2.5085 - val_accuracy: 0.5976\n",
            "Epoch 99/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 1.9690 - accuracy: 0.6899 - val_loss: 2.5502 - val_accuracy: 0.5926\n",
            "Epoch 100/100\n",
            "390/390 [==============================] - 22s 56ms/step - loss: 1.9685 - accuracy: 0.6913 - val_loss: 2.5407 - val_accuracy: 0.5917\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7Wa1m6T8ZYq",
        "colab_type": "code",
        "outputId": "783ed1bd-dbbb-4e05-edde-119df44d4cd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "score = model.evaluate(x_test,y_test)\n",
        "print(\"Test Loss: \",score[0])\n",
        "print(\"Test Accuracy: \",score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 4s 371us/step\n",
            "Test Loss:  2.5406960456848147\n",
            "Test Accuracy:  0.59170001745224\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}