{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dig_MNSIT_From_Scratch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/poornaprag/deep-learning/blob/master/Dig_MNSIT_From_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "369nE8DDs0Eg",
        "colab_type": "text"
      },
      "source": [
        "Graded Assignment 1  \n",
        "Implementing MNIST Digit Classifier From Scratch  \n",
        "Deep Learning  \n",
        "Spring 2020  \n",
        "Author: Poornapragna Vadiraj  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ez2wGNMI-8Z",
        "colab_type": "text"
      },
      "source": [
        "MNIST Classification has been done many times before but what makes this assignment challening is that it should be done from scratch without using higher level libraries or frameworks (like Keras, TF)\n",
        "\n",
        "I will enumerate the high level requirements for the assignment:\n",
        "\n",
        "1. The notebook needs to have a mini batch gradient descent along with an acceptable learning rate.\n",
        "\n",
        "2. The application should perform drop out -- try multiple dropout levels and select the one that fits best. \n",
        "\n",
        "3. The code should correctly configure the random weights of the network.\n",
        "\n",
        "4. The code should allow simple image improvements to supplement the training data \n",
        "\n",
        "5. The code should use 3 or more layers for training.\n",
        "\n",
        "6. The application must continue to use the relu activation layer in the right place, such as python application"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WG82S44SDTgg",
        "colab_type": "code",
        "outputId": "e767a35a-8521-4733-a05a-2e37fe212c14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "# Load all the dependencies\n",
        "import numpy as np\n",
        "import keras\n",
        "# Please note that I am only using Keras for importing the initial dataset only\n",
        "# Its functions/classes have not been used for the actual classification\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import trange\n",
        "from keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHQoRZ7LOpqZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Python class to emulate a single neural network layer\n",
        "class NN_Layer:\n",
        "  def __init__(self):\n",
        "    self.wgts = np.zeros(shape=(input.shape[1], 10))\n",
        "    bs = np.zeros(shape=(10,))\n",
        "\n",
        "  def forward(self, ip):\n",
        "        op = np.matmul(ip, self.wgts) + bs\n",
        "        return op"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtxTR787PXiO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ReLU dense layer with learning rate inputs\n",
        "class ReLuLayer(NN_Layer):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def backward(self, ip, grad_op):\n",
        "        relu_g = ip > 0\n",
        "        return grad_op*relu_g \n",
        "    \n",
        "    def forward(self, ip):\n",
        "        return np.maximum(0,ip)\n",
        "\n",
        "class DenseLayer(NN_Layer):\n",
        "    def __init__(self, ips, ops, learning_rate=0.1):\n",
        "        self.wgts = np.random.randn(ips, ops)*0.01  # Normal dist randomization\n",
        "        self.bs = np.zeros(ops)\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "    def forward(self,input):\n",
        "        return np.matmul(input, self.wgts) + self.bs\n",
        "\n",
        "    def backward(self,ip,grad_op):\n",
        "        grad_ip = np.dot(grad_op,np.transpose(self.wgts))\n",
        "        grad_wgts = np.transpose(np.dot(np.transpose(grad_op),ip))\n",
        "        grad_bs = np.sum(grad_op, axis = 0)\n",
        "        \n",
        "        # SGD\n",
        "        self.bs = self.bs - self.learning_rate * grad_bs\n",
        "        self.wgts = self.wgts - self.learning_rate * grad_wgts\n",
        "        return grad_ip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoEPifeoKqhv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loss functions\n",
        "def softcentropy(lgs,ref_ans):\n",
        "    log_ans = lgs[np.arange(len(lgs)),ref_ans]\n",
        "    finalEnt = - log_ans + np.log(np.sum(np.exp(lgs),axis=-1))\n",
        "    return finalEnt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7N7A12uKsvd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gradient_version_soft(lgs,ref_ans):\n",
        "    oneans = np.zeros_like(lgs)\n",
        "    oneans[np.arange(len(lgs)),ref_ans] = 1 \n",
        "    smax = np.exp(lgs) / np.exp(lgs).sum(axis=-1,keepdims=True) \n",
        "    return (- oneans + smax) / lgs.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mv9exEVEKu_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dataLoad(flatten=False):\n",
        "    (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data() # This is where the Keras dependency is used\n",
        "    # Normalizing X \n",
        "    x_train = x_train.astype(float) / 255.\n",
        "    x_test = x_test.astype(float) / 255.\n",
        "    # Validation dataset\n",
        "    x_train, x_val = x_train[:-10000], x_train[-10000:]\n",
        "    y_train, y_val = y_train[:-10000], y_train[-10000:]\n",
        "    if flatten:\n",
        "        x_train = x_train.reshape([x_train.shape[0], -1])\n",
        "        x_val = x_val.reshape([x_val.shape[0], -1])\n",
        "        x_test = x_test.reshape([x_test.shape[0], -1])\n",
        "    return x_train, y_train, x_val, y_val, x_test, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCazZhgMKzS0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, y_train, x_val, y_val, x_test, y_test = dataLoad(flatten=True)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0S8qi9BmPiD",
        "colab_type": "text"
      },
      "source": [
        "Data Augmentation using Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3G1_ZOEmI9_",
        "colab_type": "code",
        "outputId": "623b21ae-1dea-43c2-c9da-ae3f81f433f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "(X_Train, Y_train), (X_test, Y_test) = keras.datasets.cifar10.load_data()\n",
        "ImageDataGenerator(featurewise_std_normalization=True,rotation_range=20,horizontal_flip=True).fit(X_Train)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:348: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, which overrides setting of `featurewise_center`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0N-1Zwp2Wbwq",
        "colab_type": "text"
      },
      "source": [
        "Creating an empty list to represent the neural network, and appending layers with different learning rates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_zulur2WcL-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhaVlzfLWbTx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTwsKb9XVBmL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "neuralnet = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRrTZTY-WRvO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Input\n",
        "neuralnet.append(DenseLayer(x_train.shape[1],100))\n",
        "neuralnet.append(ReLuLayer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_012jQnEWRc_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hidden\n",
        "neuralnet.append(DenseLayer(100,200,learning_rate=0.2))\n",
        "neuralnet.append(ReLuLayer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE3QOw59WROq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hidden\n",
        "neuralnet.append(DenseLayer(200,200,learning_rate=0.1))\n",
        "neuralnet.append(ReLuLayer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6YYG8v1WQ7d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Output\n",
        "neuralnet.append(DenseLayer(200,10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgnpHHVDK3N_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Passing through the neural network we generated previously as input and iterating over all layers and calling forward feature on each layer.\n",
        "def forward(neuralnet, x):\n",
        "    ip = x\n",
        "    acts = []\n",
        "    for i in range(len(neuralnet)):\n",
        "        acts.append(neuralnet[i].forward(x))\n",
        "        x = neuralnet[i].forward(x)\n",
        "    return acts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yg2DVwp9LAeb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(neuralnet,x):\n",
        "    lgs = forward(neuralnet,x)[-1]\n",
        "    return lgs.argmax(axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zkqsv1pNYqVO",
        "colab_type": "text"
      },
      "source": [
        "Batchwise training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlZnyYCmLClG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(nn,x,y):\n",
        "    # The gradient and loss before training\n",
        "    layer_acts = forward(nn,x)\n",
        "    lgs = layer_acts[-1]\n",
        "    \n",
        "    loss = softcentropy(lgs,y)\n",
        "    l_grad = gradient_version_soft(lgs,y)\n",
        "    for i in range(1, len(nn)):\n",
        "        l_grad = nn[len(nn) - i].backward(layer_acts[len(nn) - i - 1], l_grad)\n",
        "    return np.mean(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXppCiNxJnu4",
        "colab_type": "text"
      },
      "source": [
        "Mini Batch Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gSl9Wj0LE08",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_into_batches(ips, goals, sizeBatch, randomize_each_time=False):\n",
        "    if randomize_each_time:\n",
        "        indexes = np.random.permutation(len(ips))\n",
        "    for first_index in trange(0, len(ips) - sizeBatch + 1, sizeBatch):\n",
        "        if randomize_each_time:\n",
        "            ext = indexes[first_index:first_index + sizeBatch]\n",
        "        else:\n",
        "            ext = slice(first_index, first_index + sizeBatch)\n",
        "        yield ips[ext], goals[ext]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjxSeUFzpnuP",
        "colab_type": "text"
      },
      "source": [
        "Final training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aB0PaFqdLHvY",
        "colab_type": "code",
        "outputId": "403e3956-4be7-4b2f-89f7-1774dbcf37c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        }
      },
      "source": [
        "training_data_logger = []\n",
        "validation_data_logger = []\n",
        "# For each cycle, we split the training data into batches (mini batch) and use that for further processing\n",
        "for iteration in range(5):\n",
        "    for batchX,batchY in split_into_batches(x_train,y_train,sizeBatch=32,randomize_each_time=True):\n",
        "        train(neuralnet,batchX,batchY)\n",
        "    # Log training and validation results to the log lists\n",
        "    training_data_logger.append(np.mean(predict(neuralnet,x_train)==y_train))\n",
        "    validation_data_logger.append(np.mean(predict(neuralnet,x_val)==y_val))\n",
        "    \n",
        "    print(\"\\n Round\",iteration)\n",
        "    print(\"\\n Train accuracy:\",training_data_logger[-1])\n",
        "    print(\"\\n Validation accuracy:\",validation_data_logger[-1])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1562/1562 [00:04<00:00, 341.94it/s]\n",
            "  2%|▏         | 33/1562 [00:00<00:04, 311.84it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Round 0\n",
            "\n",
            " Train accuracy: 0.11356\n",
            "\n",
            " Validation accuracy: 0.1064\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1562/1562 [00:04<00:00, 344.88it/s]\n",
            "  2%|▏         | 35/1562 [00:00<00:04, 346.32it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Round 1\n",
            "\n",
            " Train accuracy: 0.4613\n",
            "\n",
            " Validation accuracy: 0.4845\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1562/1562 [00:04<00:00, 345.31it/s]\n",
            "  2%|▏         | 34/1562 [00:00<00:04, 333.92it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Round 2\n",
            "\n",
            " Train accuracy: 0.737\n",
            "\n",
            " Validation accuracy: 0.7584\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1562/1562 [00:04<00:00, 342.57it/s]\n",
            "  2%|▏         | 37/1562 [00:00<00:04, 368.50it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Round 3\n",
            "\n",
            " Train accuracy: 0.79716\n",
            "\n",
            " Validation accuracy: 0.8114\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1562/1562 [00:04<00:00, 347.80it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Round 4\n",
            "\n",
            " Train accuracy: 0.84438\n",
            "\n",
            " Validation accuracy: 0.8588\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFFOJpOePxTf",
        "colab_type": "text"
      },
      "source": [
        "**Results**  \n",
        "On average getting about 90% accuracy after 5 training sessions.\n",
        "Further training does not seem to improve accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pc9yWgO5LLUb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = predict(neuralnet,x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRFRj0teus1X",
        "colab_type": "text"
      },
      "source": [
        "Let's look at the confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qKLx18at3cr",
        "colab_type": "code",
        "outputId": "8a89b4d3-1a34-4079-9b28-4ba728e397df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_test,y_pred)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 912,    0,    4,    6,    2,   24,   21,    4,    5,    2],\n",
              "       [   0, 1114,    2,    5,    2,    2,    2,    2,    6,    0],\n",
              "       [  13,   16,  799,   69,   22,    8,   25,   16,   57,    7],\n",
              "       [   2,    6,   20,  887,    0,   47,    4,   22,   20,    2],\n",
              "       [   1,   10,    9,    2,  877,    3,   15,    7,    5,   53],\n",
              "       [  31,    5,   11,   77,    5,  675,   22,   20,   39,    7],\n",
              "       [  19,    6,    9,    2,   20,   31,  865,    2,    4,    0],\n",
              "       [   4,   24,   15,   14,   17,    4,    2,  911,    4,   33],\n",
              "       [  10,   20,   14,   48,   18,   67,    9,   10,  757,   21],\n",
              "       [  11,   11,    6,   16,  127,   13,    1,   60,   24,  740]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TARthrZBuiVe",
        "colab_type": "text"
      },
      "source": [
        "Let us compute the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dr6c2PxAuB9g",
        "colab_type": "code",
        "outputId": "7c142925-385d-4c81-a872-65259f94cbb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8537"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVyXhG4kXxN-",
        "colab_type": "text"
      },
      "source": [
        "MNIST "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8hzxsyiX09Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
